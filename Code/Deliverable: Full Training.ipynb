{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import argparse\n",
    "\n",
    "from timeit import default_timer\n",
    "\n",
    "from lib.utilities3 import *\n",
    "from lib.datahelper import *\n",
    "from lib.dataset_raw import *\n",
    "from lib.fno import *\n",
    "\n",
    "from lib.memorytracking import save_memory_usage\n",
    "import datetime\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODES = 8\n",
    "WIDTH = 128\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# if we should use cuda\n",
    "GPU = True\n",
    "# if we should use full version of dataset\n",
    "DATASET_BIG = False\n",
    "EPOCHS = 1000\n",
    "# how often to save model/residual graphs\n",
    "SAVE_INTERVAL = 10\n",
    "\n",
    "# change this on every experiment\n",
    "EXPERIMENT = f\"encoded-batchsize{BATCH_SIZE}-{'gpu' if GPU else 'cpu'}-{'BIG' if DATASET_BIG else 'SMALL'}-{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "RUN DETAILS\n",
      "========================================\n",
      "MODES=8, WIDTH=128, BATCH SIZE=8, GPU=True, BIG DATASET=False, EPOCHS=1000, SAVE INTERVAL=10\n",
      "\n",
      "========================================\n",
      "BEGIN RUN\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "print (\"=\" * 40)\n",
    "print (\"RUN DETAILS\")\n",
    "print (\"=\" * 40)\n",
    "\n",
    "print (f\"MODES={MODES}, WIDTH={WIDTH}, BATCH SIZE={BATCH_SIZE}, GPU={GPU}, BIG DATASET={DATASET_BIG}, EPOCHS={EPOCHS}, SAVE INTERVAL={SAVE_INTERVAL}\")\n",
    "print()\n",
    "\n",
    "print (\"=\" * 40)\n",
    "print (\"BEGIN RUN\")\n",
    "print (\"=\" * 40)\n",
    "\n",
    "filename = '../Data/DatVel5000_Sou10_Rec10_Dim100x100_Gradient_Encoded.npz'\n",
    "if not DATASET_BIG:\n",
    "    filename = '../Data/DatVel30_Sou100_Rec100_Dim100x100_Downsampled_Encoded.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset\n"
     ]
    }
   ],
   "source": [
    "print (\"loading dataset\")\n",
    "with np.load(filename, allow_pickle=True) as fid:\n",
    "    train_data = EikonalDatasetRaw(fid, 'train')\n",
    "    test_data = EikonalDatasetRaw(fid, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader_single = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "\n",
    "kernel_metadata_file='./lib/largefile-kernels-metadata.pkl'\n",
    "\n",
    "with open(kernel_metadata_file, 'rb') as f:\n",
    "    kernel_metadata = pickle.loads(f.read())\n",
    "\n",
    "y_normalizer = UnitGaussianNormalizer(\n",
    "    meanval=kernel_metadata['mean'],\n",
    "    stdval=kernel_metadata['std'],\n",
    "    maxval=kernel_metadata['max'],\n",
    "    minval=kernel_metadata['min'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training!!\n",
      "epoch 1\n",
      "epoch: 1, \tl2 train: 0.9328428958892823 \tl2 test: 0.981662070274353\n",
      "epoch: 0, \tl2 train: 0.9328428958892823 \tl2 test: 0.981662070274353\n",
      "epoch 2\n",
      "epoch: 2, \tl2 train: 0.8987031234741211 \tl2 test: 0.930295093536377\n",
      "epoch: 0, \tl2 train: 0.9328428958892823 \tl2 test: 0.981662070274353\n",
      "epoch: 1, \tl2 train: 0.8987031234741211 \tl2 test: 0.930295093536377\n",
      "epoch 3\n",
      "epoch: 3, \tl2 train: 0.875385294342041 \tl2 test: 0.8965552968978882\n",
      "epoch: 0, \tl2 train: 0.9328428958892823 \tl2 test: 0.981662070274353\n",
      "epoch: 1, \tl2 train: 0.8987031234741211 \tl2 test: 0.930295093536377\n",
      "epoch: 2, \tl2 train: 0.875385294342041 \tl2 test: 0.8965552968978882\n",
      "epoch 4\n"
     ]
    }
   ],
   "source": [
    "######## TRAINING\n",
    "\n",
    "print (\"begin training!!\")\n",
    "fno_model = FNO2d(MODES, MODES, WIDTH)\n",
    "if GPU:\n",
    "    fno_model = fno_model.cuda()\n",
    "\n",
    "test_fno = []\n",
    "train_fno = []\n",
    "log_test_fno = []\n",
    "log_train_fno = []\n",
    "\n",
    "optimizer = torch.optim.AdamW(fno_model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "myloss = LpLoss(size_average=False)\n",
    "\n",
    "if GPU:\n",
    "    torch.cuda.reset_max_memory_allocated()\n",
    "    torch.cuda.empty_cache()\n",
    "    before_memory = torch.cuda.memory_allocated()\n",
    "\n",
    "    t1 = default_timer()\n",
    "    y_normalizer.cuda()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "prefix = EXPERIMENT\n",
    "\n",
    "for ep in range(1, EPOCHS + 1):\n",
    "    print (f\"epoch {ep}\")\n",
    "    if ep < 5 or ep % SAVE_INTERVAL == 0:\n",
    "        save_models(fno_model, ep, MODES, WIDTH, prefix=prefix)\n",
    "\n",
    "    fno_model.eval()\n",
    "    test_l2 = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            if GPU:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "            x, y = x.float(), y.float()\n",
    "\n",
    "            out = fno_model(x)\n",
    "            out = out.squeeze(-1)\n",
    "            y = y_normalizer.decode(y)\n",
    "            if GPU:\n",
    "                y = y.cuda()\n",
    "\n",
    "            out = y_normalizer.decode(out)\n",
    "\n",
    "            curr_loss = myloss(out, y.view(len(y),-1)).item()\n",
    "            test_l2 += curr_loss\n",
    "\n",
    "    fno_model.train()\n",
    "    train_l2 = 0\n",
    "    for x, y in train_loader:\n",
    "        if GPU:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        x, y = x.float(), y.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = fno_model(x)\n",
    "        if GPU:\n",
    "            out = out.cuda()\n",
    "        out = out.squeeze(-1)\n",
    "        out = y_normalizer.decode(out)\n",
    "        if GPU:\n",
    "            out = out.cuda()\n",
    "        y = y_normalizer.decode(y)\n",
    "        if GPU:\n",
    "            y = y.cuda()\n",
    "\n",
    "        loss = myloss(out, y.view(len(y),-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        train_l2 += loss.item()\n",
    "\n",
    "    train_l2/= len(train_data)\n",
    "    test_l2 /= len(test_data)\n",
    "    print(f\"epoch: {ep}, \\tl2 train: {train_l2} \\tl2 test: {test_l2}\")\n",
    "\n",
    "    train_fno.append(train_l2)\n",
    "    test_fno.append(test_l2)\n",
    "    log_train_fno.append(math.log(train_l2))\n",
    "    log_test_fno.append(math.log(test_l2))\n",
    "\n",
    "    save_losses(train_fno, test_fno, log_train_fno, log_test_fno, MODES, WIDTH, prefix=prefix)\n",
    "\n",
    "    if ep < 5 or ep % SAVE_INTERVAL == 0:\n",
    "        plot_loss_curves(train_fno, test_fno, log_train_fno, log_test_fno, MODES, WIDTH, ep, prefix=prefix)\n",
    "\n",
    "t2 = default_timer()\n",
    "max_memory = torch.cuda.max_memory_allocated() - before_memory\n",
    "print(f'Max Memory Allocated: {max_memory} Time: {t2-t1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garbage Collection\n",
    "\n",
    "We need to clean up unused variables after every run because otherwise CUDA runs out of memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (FNO)",
   "language": "python",
   "name": "ejpatel_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
